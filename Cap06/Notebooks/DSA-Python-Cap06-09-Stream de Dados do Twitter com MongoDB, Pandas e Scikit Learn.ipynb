{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Python Fundamentos - Cap√≠tulo 6</font>\n",
    "\n",
    "## Download: http://github.com/dsacademybr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream de Dados do Twitter com MongoDB, Pandas e Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conex√£o com o Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\anaconda3\\lib\\site-packages (from tweepy) (2.20.1)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\anaconda3\\lib\\site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\anaconda3\\lib\\site-packages (from tweepy) (1.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2018.10.15)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in c:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Instala o pacote tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os m√≥dulos Tweepy, Datetime e Json\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja no manual em pdf como criar sua API no Twitter e configure as suas chaves abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Key\n",
    "consumer_key = \"qCDvng2oqG06iSvVq4HWYYo0G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Secret \n",
    "consumer_secret = \"09DN2U0eeXWTI5MVmD7AGn7BtDd8RCHqvLCNVry2nF8GqnmL1l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token\n",
    "access_token = \"69676973-DgaxHyDPWRLJXHoj39siWlhnkqa6n4wVvHIl8XPS5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token Secret\n",
    "access_token_secret = \"9chgtp90equSMODOQRQzdxInRbUbqa8mDpFRh5wBXSLrH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as chaves de autentica√ß√£o\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma classe para capturar os stream de dados do Twitter e \n",
    "# armazenar no MongoDB\n",
    "class MyListener(StreamListener):\n",
    "    def on_data(self, dados):\n",
    "        tweet = json.loads(dados)\n",
    "        created_at = tweet[\"created_at\"]\n",
    "        id_str = tweet[\"id_str\"]\n",
    "        text = tweet[\"text\"]\n",
    "        obj = {\"created_at\":created_at,\"id_str\":id_str,\"text\":text,}\n",
    "        tweetind = col.insert_one(obj).inserted_id\n",
    "        print (obj)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mylistener\n",
    "mylistener = MyListener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mystream\n",
    "mystream = Stream(auth, listener = mylistener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conex√£o com o MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando do PyMongo o m√≥dulo MongoClient\n",
    "from pymongo import MongoClient   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a conex√£o ao MongoDB\n",
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o banco de dados twitterdb\n",
    "db = client.twitterdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a collection \"col\"\n",
    "col = db.tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista de palavras chave para buscar nos Tweets\n",
    "keywords = ['Big Data', 'Python', 'Data Mining', 'Data Science']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando os Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Sun Dec 23 18:07:38 +0000 2018', 'id_str': '1076902163069190148', 'text': '@DShaywitz IMO a combination of factors:\\n- in onc, \"big data\" can be biased for use cases that don\\'t necessarily tr‚Ä¶ https://t.co/rKjxAnUEfp', '_id': ObjectId('5c1fceede5e3ff289025a9d4')}\n",
      "{'created_at': 'Sun Dec 23 18:07:39 +0000 2018', 'id_str': '1076902167905222664', 'text': 'OH: ‚ÄúI‚Äôm not doing machine learning or anything, just some statistics in Python until it fits.‚Äù üíÅüèº\\u200d‚ôÇÔ∏è', '_id': ObjectId('5c1fceeee5e3ff289025a9d5')}\n",
      "{'created_at': 'Sun Dec 23 18:07:42 +0000 2018', 'id_str': '1076902181188579328', 'text': 'RT @alainbejjani: Customer experience and big data have, and continue to be, front and centre for us at @MajidAlFuttaim.\\n\\nRead my latest bl‚Ä¶', '_id': ObjectId('5c1fcef1e5e3ff289025a9d6')}\n",
      "{'created_at': 'Sun Dec 23 18:07:44 +0000 2018', 'id_str': '1076902188771930112', 'text': 'Many thanks to @Babatee760 @Cyberdroidmann and @SadeeqAkintola for helping breakdown Artificial Intelligence and Da‚Ä¶ https://t.co/TWw1lo633g', '_id': ObjectId('5c1fcef5e5e3ff289025a9d7')}\n",
      "{'created_at': 'Sun Dec 23 18:07:46 +0000 2018', 'id_str': '1076902196195848193', 'text': 'Identity: we are concerned about the use of our personal data but we are happy to give it up with no incentives. Th‚Ä¶ https://t.co/UYarBd4Okm', '_id': ObjectId('5c1fcef6e5e3ff289025a9d8')}\n",
      "{'created_at': 'Sun Dec 23 18:07:54 +0000 2018', 'id_str': '1076902231985872897', 'text': 'RT @Deep_In_Depth: Top Python Libraries in 2018 in Data Science, Deep Learning, Machine Learning https://t.co/Jj0V85dWcs #DeepLearning #Mac‚Ä¶', '_id': ObjectId('5c1fcefde5e3ff289025a9d9')}\n",
      "{'created_at': 'Sun Dec 23 18:08:03 +0000 2018', 'id_str': '1076902267977121792', 'text': 'RT @vogueandcode: 2019 Goal Setting Today!! üò¨üôåüèæ\\n\\nNon-Tech Goals:\\nüî∏ Save $10k\\nüî∏ Progress to Pointe (ballet)\\nüî∏ Put on Muscle + Compete (again‚Ä¶', '_id': ObjectId('5c1fcf06e5e3ff289025a9da')}\n",
      "{'created_at': 'Sun Dec 23 18:08:04 +0000 2018', 'id_str': '1076902273404583938', 'text': 'RT @swardley: \"experience with Wardley Maps\" as a desirable skill. That\\'s about the seventh job advert I\\'ve seen which mentions my form of‚Ä¶', '_id': ObjectId('5c1fcf07e5e3ff289025a9db')}\n",
      "{'created_at': 'Sun Dec 23 18:08:06 +0000 2018', 'id_str': '1076902280086110212', 'text': 'Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/AVgTsWFFRY\\n\\n#python #Docker https://t.co/uAPDXEq5wF', '_id': ObjectId('5c1fcf09e5e3ff289025a9dc')}\n",
      "{'created_at': 'Sun Dec 23 18:08:17 +0000 2018', 'id_str': '1076902326840029186', 'text': 'RT @schmarzo: Good predictions Bill!\\n-Data More Important Than Algorithms\\n-AI/ML Moves to Apps\\n-Rise of Data Engineer &amp; Data Analyst\\n-Neuro‚Ä¶', '_id': ObjectId('5c1fcf14e5e3ff289025a9dd')}\n",
      "{'created_at': 'Sun Dec 23 18:08:21 +0000 2018', 'id_str': '1076902346209271808', 'text': 'Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/mqZt09rZaw\\n\\n#python #Docker https://t.co/sgoLQ0IOb1', '_id': ObjectId('5c1fcf19e5e3ff289025a9de')}\n",
      "{'created_at': 'Sun Dec 23 18:08:22 +0000 2018', 'id_str': '1076902349904510976', 'text': 'RT @tattoosandbones: Out of over 8000 USGS employees, only 75 are currently working.\\n\\nOnly skeleton crews for NASA, the NSF, and NOAA are w‚Ä¶', '_id': ObjectId('5c1fcf19e5e3ff289025a9df')}\n",
      "{'created_at': 'Sun Dec 23 18:08:25 +0000 2018', 'id_str': '1076902362298560513', 'text': 'RT @alexellisuk: Build your own bare-metal ARM cluster https://t.co/cUpDSXvi8K #docker #python #arm #kubernetes @Raspberry_Pi', '_id': ObjectId('5c1fcf1ce5e3ff289025a9e0')}\n",
      "{'created_at': 'Sun Dec 23 18:08:34 +0000 2018', 'id_str': '1076902400412266496', 'text': 'Big Data; The exponential growth of data.', '_id': ObjectId('5c1fcf28e5e3ff289025a9e1')}\n",
      "{'created_at': 'Sun Dec 23 18:08:40 +0000 2018', 'id_str': '1076902426257645573', 'text': '„Äê¬•12,600‚Üí¬•1,800„ÄëUdemy„Äé„Äê‰∏ñÁïå„Åß5‰∏á‰∫∫„ÅåÂèóË¨õ„ÄëÂÆüË∑µ Python „Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ„Äè„Ç≥„Éº„Çπ„ÅÆÈôêÂÆö„ÇØ„Éº„Éù„É≥\\n\\nhttps://t.co/MtbG6GYJPf\\n\\n#udemy #„ÇØ„Éº„Éù„É≥', '_id': ObjectId('5c1fcf36e5e3ff289025a9e2')}\n",
      "{'created_at': 'Sun Dec 23 18:08:47 +0000 2018', 'id_str': '1076902453256175616', 'text': 'I guess it is how you define a wave. Decrease in GOP voters on the rolls. Increase in Dem registration. Higher numb‚Ä¶ https://t.co/3kgiSwCaON', '_id': ObjectId('5c1fcf39e5e3ff289025a9e3')}\n",
      "{'created_at': 'Sun Dec 23 18:08:48 +0000 2018', 'id_str': '1076902457190608896', 'text': 'RT @whyevernotso: Names for collections of code in various languages:\\n\\nA pile of JavaScript\\n\\nA crystal of Haskell\\n\\nAn undefinedness of C++‚Ä¶', '_id': ObjectId('5c1fcf3ae5e3ff289025a9e4')}\n",
      "{'created_at': 'Sun Dec 23 18:08:54 +0000 2018', 'id_str': '1076902484864454656', 'text': 'My general suspicion is that decades of managerialism hasn‚Äôt helped with essence of new drug discovery but has made‚Ä¶ https://t.co/zDPAf0eDnk', '_id': ObjectId('5c1fcf3ae5e3ff289025a9e5')}\n",
      "{'created_at': 'Sun Dec 23 18:09:00 +0000 2018', 'id_str': '1076902509527076865', 'text': 'RT @Ahmadanii2: Big Data, Meager returns? ‚Äì digital HKS ‚Äì Medium https://t.co/dx6bUk962X #Transformation #AI #Wearables #UX https://t.co/zD‚Ä¶', '_id': ObjectId('5c1fcf40e5e3ff289025a9e6')}\n",
      "{'created_at': 'Sun Dec 23 18:09:01 +0000 2018', 'id_str': '1076902513465573377', 'text': 'Hadoop: The Definitive Guide https://t.co/OnnpfaH39b #python #bigdata #hadoop @The_Academy_BOT', '_id': ObjectId('5c1fcf40e5e3ff289025a9e7')}\n",
      "{'created_at': 'Sun Dec 23 18:09:02 +0000 2018', 'id_str': '1076902518217732097', 'text': 'If statement from a number to infinity https://t.co/HmmV56Mutm #python', '_id': ObjectId('5c1fcf42e5e3ff289025a9e8')}\n",
      "{'created_at': 'Sun Dec 23 18:09:06 +0000 2018', 'id_str': '1076902532855738368', 'text': 'Day: 4/100\\nI started Data Structures and Algorithms Specialization in Coursera this day. I completed the first week‚Ä¶ https://t.co/4TVE3bvhVf', '_id': ObjectId('5c1fcf46e5e3ff289025a9e9')}\n",
      "{'created_at': 'Sun Dec 23 18:09:07 +0000 2018', 'id_str': '1076902536060100608', 'text': 'RT @DrDataScientist: Big Data Processing Engines ‚Äì Which one do I use?: Part 1 https://t.co/TbxOHRPSQr #BigData #Hadoop #NoSQL https://t.co‚Ä¶', '_id': ObjectId('5c1fcf46e5e3ff289025a9ea')}\n",
      "{'created_at': 'Sun Dec 23 18:09:10 +0000 2018', 'id_str': '1076902548169256961', 'text': 'RT @developer_tv: Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/mqZt09rZaw\\n\\n#python #Docker https://t.co/sg‚Ä¶', '_id': ObjectId('5c1fcf49e5e3ff289025a9eb')}\n",
      "{'created_at': 'Sun Dec 23 18:09:10 +0000 2018', 'id_str': '1076902549540749315', 'text': 'RT @computer__pro: Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/AVgTsWFFRY\\n\\n#python #Docker https://t.co/u‚Ä¶', '_id': ObjectId('5c1fcf49e5e3ff289025a9ec')}\n",
      "{'created_at': 'Sun Dec 23 18:09:10 +0000 2018', 'id_str': '1076902552044740609', 'text': 'RT @kdnuggets: 60+ #Free #Books on #BigData, #DataScience, #DataMining, #MachineLearning, #Python, R, and more #KDN https://t.co/aNNzpUdH1t', '_id': ObjectId('5c1fcf4ae5e3ff289025a9ed')}\n",
      "{'created_at': 'Sun Dec 23 18:09:12 +0000 2018', 'id_str': '1076902558667497472', 'text': 'RT @IamFarZanaEva: Day: 4/100\\nI started Data Structures and Algorithms Specialization in Coursera this day. I completed the first week of c‚Ä¶', '_id': ObjectId('5c1fcf4be5e3ff289025a9ee')}\n",
      "{'created_at': 'Sun Dec 23 18:09:15 +0000 2018', 'id_str': '1076902571917361154', 'text': 'RT @GurayYildirimTR: Python, R, Pandas, Jupyter, Spark, DASK, machine learning, big data, data visualization, SQL, deep learning gibi veri‚Ä¶', '_id': ObjectId('5c1fcf4ee5e3ff289025a9ef')}\n",
      "{'created_at': 'Sun Dec 23 18:09:24 +0000 2018', 'id_str': '1076902609909415941', 'text': 'Identity: we say we are  concerned about the use of our personal data, yet we happily give it up without incentives‚Ä¶ https://t.co/Fos1XnumkW', '_id': ObjectId('5c1fcf57e5e3ff289025a9f0')}\n",
      "{'created_at': 'Sun Dec 23 18:09:29 +0000 2018', 'id_str': '1076902628578213888', 'text': 'RT @kdnuggets: 60+ #Free #Books on #BigData, #DataScience, #DataMining, #MachineLearning, #Python, R, and more #KDN https://t.co/aNNzpUdH1t', '_id': ObjectId('5c1fcf5ce5e3ff289025a9f1')}\n",
      "{'created_at': 'Sun Dec 23 18:09:31 +0000 2018', 'id_str': '1076902637008838657', 'text': 'RT @CaffeinatedT: #ImTiredOf being broke everytime that I always ask money for data bundles from Mom ,so I can go on twitter &amp; act Big‚Ä¶', '_id': ObjectId('5c1fcf5ee5e3ff289025a9f2')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Sun Dec 23 18:09:37 +0000 2018', 'id_str': '1076902665093869568', 'text': 'RT @lwp_: #C√≥digo de #Python - Dia de la semana en cualquier fecha. https://t.co/3ucCJbG0yG https://t.co/utEfCEh9jR', '_id': ObjectId('5c1fcf65e5e3ff289025a9f3')}\n",
      "{'created_at': 'Sun Dec 23 18:09:40 +0000 2018', 'id_str': '1076902675281784832', 'text': 'Filmin giri≈üi Monthy Python The Holy Grail in giri≈üini anƒ±msattƒ±. Zaten b√∂yle bir giri≈ü ile oradan tatlar alacaksƒ±n‚Ä¶ https://t.co/1Oba5oHD8J', '_id': ObjectId('5c1fcf67e5e3ff289025a9f4')}\n",
      "{'created_at': 'Sun Dec 23 18:09:42 +0000 2018', 'id_str': '1076902684978962432', 'text': '@codemickeycode Glad you asked! It‚Äôs a python 3 implementation on tiny Microcontrollers designed for beginners and‚Ä¶ https://t.co/fOpWDB3MIj', '_id': ObjectId('5c1fcf69e5e3ff289025a9f5')}\n",
      "{'created_at': 'Sun Dec 23 18:09:42 +0000 2018', 'id_str': '1076902686405074950', 'text': 'RT @ThePSF: SciPy 1.2.0 is the culmination of 6 months of hard work - https://t.co/U12J1yz1nS. This will be the last SciPy release to suppo‚Ä¶', '_id': ObjectId('5c1fcf6ae5e3ff289025a9f6')}\n",
      "{'created_at': 'Sun Dec 23 18:09:48 +0000 2018', 'id_str': '1076902710413119488', 'text': 'Send SMS using Python ‚Äì Shubham Jante ‚Äì Medium https://t.co/rvVPJWG9PL', '_id': ObjectId('5c1fcf6fe5e3ff289025a9f7')}\n",
      "{'created_at': 'Sun Dec 23 18:09:48 +0000 2018', 'id_str': '1076902711357030402', 'text': 'RT @IamFarZanaEva: Day: 4/100\\nI started Data Structures and Algorithms Specialization in Coursera this day. I completed the first week of c‚Ä¶', '_id': ObjectId('5c1fcf70e5e3ff289025a9f8')}\n",
      "{'created_at': 'Sun Dec 23 18:09:59 +0000 2018', 'id_str': '1076902756902944768', 'text': 'RT @sumit12dec: #chatbots #facebook #developers #programmers #entrepreneurs https://t.co/HhxKKIrL4S', '_id': ObjectId('5c1fcf7fe5e3ff289025a9f9')}\n",
      "{'created_at': 'Sun Dec 23 18:10:01 +0000 2018', 'id_str': '1076902765157326850', 'text': '#Discount | 48 Best #Development Courses \\n\\nhttps://t.co/SC8ssSfQ6U\\n\\n#eLearning #OnlineLearning #OnlineCourses‚Ä¶ https://t.co/3bnjqGTnGd', '_id': ObjectId('5c1fcf83e5e3ff289025a9fa')}\n",
      "{'created_at': 'Sun Dec 23 18:10:02 +0000 2018', 'id_str': '1076902768240140288', 'text': 'robin8-utils 0.2.0 #Python https://t.co/U1gbtxokNn via @krachik', '_id': ObjectId('5c1fcf83e5e3ff289025a9fb')}\n",
      "{'created_at': 'Sun Dec 23 18:10:03 +0000 2018', 'id_str': '1076902772199620608', 'text': 'HPE to Buy Big Data Infrastructure Startup BlueData https://t.co/3FsL1GLECv https://t.co/F5xAL7QW8T', '_id': ObjectId('5c1fcf83e5e3ff289025a9fc')}\n",
      "{'created_at': 'Sun Dec 23 18:10:03 +0000 2018', 'id_str': '1076902773344464896', 'text': 'RT @trengriffin: Since Santa operates a nonprofit, the best use cases for machine learning and data science are related to challenges like‚Ä¶', '_id': ObjectId('5c1fcf88e5e3ff289025a9fd')}\n",
      "{'created_at': 'Sun Dec 23 18:10:04 +0000 2018', 'id_str': '1076902776767111168', 'text': 'RT @ThePSF: SciPy 1.2.0 is the culmination of 6 months of hard work - https://t.co/U12J1yz1nS. This will be the last SciPy release to suppo‚Ä¶', '_id': ObjectId('5c1fcf88e5e3ff289025a9fe')}\n",
      "{'created_at': 'Sun Dec 23 18:10:05 +0000 2018', 'id_str': '1076902780000976902', 'text': 'Machine Learning for Data Science #datascience https://t.co/XjjDXZzc9l', '_id': ObjectId('5c1fcf88e5e3ff289025a9ff')}\n",
      "{'created_at': 'Sun Dec 23 18:10:08 +0000 2018', 'id_str': '1076902794697867265', 'text': 'RT @samlightstone: Using big data to predict the future https://t.co/nfhj7ywpn8', '_id': ObjectId('5c1fcf88e5e3ff289025aa00')}\n",
      "{'created_at': 'Sun Dec 23 18:10:10 +0000 2018', 'id_str': '1076902800678780928', 'text': 'RT @Piper_Thibodeau: Daily Paint 2223. Snow Ball Python\\nPrints available at: https://t.co/xWB2EWT4af    \\nFor full res WIPs, art, videos and‚Ä¶', '_id': ObjectId('5c1fcf88e5e3ff289025aa01')}\n",
      "{'created_at': 'Sun Dec 23 18:10:11 +0000 2018', 'id_str': '1076902805636550658', 'text': 'RT @The_Academy_BOT: Hadoop: The Definitive Guide https://t.co/OnnpfaH39b #python #bigdata #hadoop @The_Academy_BOT', '_id': ObjectId('5c1fcf88e5e3ff289025aa02')}\n",
      "{'created_at': 'Sun Dec 23 18:10:11 +0000 2018', 'id_str': '1076902806928408576', 'text': 'RT @developer_tv: Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/mqZt09rZaw\\n\\n#python #Docker https://t.co/sg‚Ä¶', '_id': ObjectId('5c1fcf89e5e3ff289025aa03')}\n",
      "{'created_at': 'Sun Dec 23 18:10:11 +0000 2018', 'id_str': '1076902807519805440', 'text': \"RT @Medium: The most powerful tech companies on this planet\\u200a \\u200ahave for years worked in tandem to set terms on the value of your data. That'‚Ä¶\", '_id': ObjectId('5c1fcf8ae5e3ff289025aa04')}\n",
      "{'created_at': 'Sun Dec 23 18:10:11 +0000 2018', 'id_str': '1076902807998029824', 'text': 'RT @computer__pro: Docker Development WorkFlow\\u200a‚Äî\\u200aa guide with Flask and Postgres\\n\\n‚òû https://t.co/AVgTsWFFRY\\n\\n#python #Docker https://t.co/u‚Ä¶', '_id': ObjectId('5c1fcf8ae5e3ff289025aa05')}\n",
      "{'created_at': 'Sun Dec 23 18:10:20 +0000 2018', 'id_str': '1076902842819055617', 'text': '@Madaboutequus @ReclaimTheBody @my_real_name @Complex_PTSD @bettydooda @WheyProtein13 @solongsweeties‚Ä¶ https://t.co/QwffuvIT2j', '_id': ObjectId('5c1fcf8fe5e3ff289025aa06')}\n",
      "{'created_at': 'Sun Dec 23 18:10:20 +0000 2018', 'id_str': '1076902845566341120', 'text': 'RT @Ananna16: #Discount | 48 Best #Development Courses \\n\\nhttps://t.co/SC8ssSfQ6U\\n\\n#eLearning #OnlineLearning #OnlineCourses #udemydeals #ud‚Ä¶', '_id': ObjectId('5c1fcf90e5e3ff289025aa07')}\n",
      "{'created_at': 'Sun Dec 23 18:10:26 +0000 2018', 'id_str': '1076902870128177152', 'text': 'RT @Jadirectivestwt: #ChristmasHoliday #Deals Online #Courses &amp; #Tutorials \\n\\nhttps://t.co/SETGwUM2lV\\n\\nDeepLearning #MachineLearning #Unity‚Ä¶', '_id': ObjectId('5c1fcf95e5e3ff289025aa08')}\n",
      "{'created_at': 'Sun Dec 23 18:10:28 +0000 2018', 'id_str': '1076902878567153664', 'text': 'RT @samlightstone: Using big data to predict the future https://t.co/nfhj7ywpn8', '_id': ObjectId('5c1fcf97e5e3ff289025aa09')}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1614\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6a9070444200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Iniciando o filtro e gravando os tweets no MongoDB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmystream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m                 \u001b[0mstripped_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mline\u001b[0m \u001b[1;31m# line is sometimes None so we need to check here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstripped_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[1;34m(self, sep)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    544\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;31m# Read the next chunk size from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunk size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The read operation timed out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[1;34m(sock, timeout)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msocket\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0mexpired\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \"\"\"\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mselect_wait_for_socket\u001b[1;34m(sock, read, write, timeout)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# thing.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mrready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mxready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[1;34m(fn, timeout)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Modern Python, that retries syscalls by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Old and broken Pythons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iniciando o filtro e gravando os tweets no MongoDB\n",
    "mystream.filter(track=keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> Pressione o bot√£o Stop na barra de ferramentas para encerrar a captura dos Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultando os Dados no MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5c1fceede5e3ff289025a9d4'),\n",
       " 'created_at': 'Sun Dec 23 18:07:38 +0000 2018',\n",
       " 'id_str': '1076902163069190148',\n",
       " 'text': '@DShaywitz IMO a combination of factors:\\n- in onc, \"big data\" can be biased for use cases that don\\'t necessarily tr‚Ä¶ https://t.co/rKjxAnUEfp'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando um documento no collection\n",
    "col.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise de Dados com Pandas e Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataset com dados retornados do MongoDB\n",
    "dataset = [{\"created_at\": item[\"created_at\"], \"text\": item[\"text\"],} for item in col.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o m√≥dulo Pandas para trabalhar com datasets em Python\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir do dataset \n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Dec 23 18:07:38 +0000 2018</td>\n",
       "      <td>@DShaywitz IMO a combination of factors:\\n- in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Dec 23 18:07:39 +0000 2018</td>\n",
       "      <td>OH: ‚ÄúI‚Äôm not doing machine learning or anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Dec 23 18:07:42 +0000 2018</td>\n",
       "      <td>RT @alainbejjani: Customer experience and big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Dec 23 18:07:44 +0000 2018</td>\n",
       "      <td>Many thanks to @Babatee760 @Cyberdroidmann and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Dec 23 18:07:46 +0000 2018</td>\n",
       "      <td>Identity: we are concerned about the use of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Dec 23 18:07:54 +0000 2018</td>\n",
       "      <td>RT @Deep_In_Depth: Top Python Libraries in 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Dec 23 18:08:03 +0000 2018</td>\n",
       "      <td>RT @vogueandcode: 2019 Goal Setting Today!! üò¨üôå...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sun Dec 23 18:08:04 +0000 2018</td>\n",
       "      <td>RT @swardley: \"experience with Wardley Maps\" a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun Dec 23 18:08:06 +0000 2018</td>\n",
       "      <td>Docker Development WorkFlow‚Ää‚Äî‚Ääa guide with Fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun Dec 23 18:08:17 +0000 2018</td>\n",
       "      <td>RT @schmarzo: Good predictions Bill!\\n-Data Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sun Dec 23 18:08:21 +0000 2018</td>\n",
       "      <td>Docker Development WorkFlow‚Ää‚Äî‚Ääa guide with Fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sun Dec 23 18:08:22 +0000 2018</td>\n",
       "      <td>RT @tattoosandbones: Out of over 8000 USGS emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sun Dec 23 18:08:25 +0000 2018</td>\n",
       "      <td>RT @alexellisuk: Build your own bare-metal ARM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sun Dec 23 18:08:34 +0000 2018</td>\n",
       "      <td>Big Data; The exponential growth of data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sun Dec 23 18:08:40 +0000 2018</td>\n",
       "      <td>„Äê¬•12,600‚Üí¬•1,800„ÄëUdemy„Äé„Äê‰∏ñÁïå„Åß5‰∏á‰∫∫„ÅåÂèóË¨õ„ÄëÂÆüË∑µ Python „Éá„Éº„Çø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sun Dec 23 18:08:47 +0000 2018</td>\n",
       "      <td>I guess it is how you define a wave. Decrease ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sun Dec 23 18:08:48 +0000 2018</td>\n",
       "      <td>RT @whyevernotso: Names for collections of cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sun Dec 23 18:08:54 +0000 2018</td>\n",
       "      <td>My general suspicion is that decades of manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sun Dec 23 18:09:00 +0000 2018</td>\n",
       "      <td>RT @Ahmadanii2: Big Data, Meager returns? ‚Äì di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sun Dec 23 18:09:01 +0000 2018</td>\n",
       "      <td>Hadoop: The Definitive Guide https://t.co/Onnp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sun Dec 23 18:09:02 +0000 2018</td>\n",
       "      <td>If statement from a number to infinity https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sun Dec 23 18:09:06 +0000 2018</td>\n",
       "      <td>Day: 4/100\\nI started Data Structures and Algo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sun Dec 23 18:09:07 +0000 2018</td>\n",
       "      <td>RT @DrDataScientist: Big Data Processing Engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sun Dec 23 18:09:10 +0000 2018</td>\n",
       "      <td>RT @developer_tv: Docker Development WorkFlow‚Ää...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sun Dec 23 18:09:10 +0000 2018</td>\n",
       "      <td>RT @computer__pro: Docker Development WorkFlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sun Dec 23 18:09:10 +0000 2018</td>\n",
       "      <td>RT @kdnuggets: 60+ #Free #Books on #BigData, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sun Dec 23 18:09:12 +0000 2018</td>\n",
       "      <td>RT @IamFarZanaEva: Day: 4/100\\nI started Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sun Dec 23 18:09:15 +0000 2018</td>\n",
       "      <td>RT @GurayYildirimTR: Python, R, Pandas, Jupyte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sun Dec 23 18:09:24 +0000 2018</td>\n",
       "      <td>Identity: we say we are  concerned about the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sun Dec 23 18:09:29 +0000 2018</td>\n",
       "      <td>RT @kdnuggets: 60+ #Free #Books on #BigData, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sun Dec 23 18:09:31 +0000 2018</td>\n",
       "      <td>RT @CaffeinatedT: #ImTiredOf being broke every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sun Dec 23 18:09:37 +0000 2018</td>\n",
       "      <td>RT @lwp_: #C√≥digo de #Python - Dia de la seman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sun Dec 23 18:09:40 +0000 2018</td>\n",
       "      <td>Filmin giri≈üi Monthy Python The Holy Grail in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sun Dec 23 18:09:42 +0000 2018</td>\n",
       "      <td>@codemickeycode Glad you asked! It‚Äôs a python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sun Dec 23 18:09:42 +0000 2018</td>\n",
       "      <td>RT @ThePSF: SciPy 1.2.0 is the culmination of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sun Dec 23 18:09:48 +0000 2018</td>\n",
       "      <td>Send SMS using Python ‚Äì Shubham Jante ‚Äì Medium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sun Dec 23 18:09:48 +0000 2018</td>\n",
       "      <td>RT @IamFarZanaEva: Day: 4/100\\nI started Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sun Dec 23 18:09:59 +0000 2018</td>\n",
       "      <td>RT @sumit12dec: #chatbots #facebook #developer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sun Dec 23 18:10:01 +0000 2018</td>\n",
       "      <td>#Discount | 48 Best #Development Courses \\n\\nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sun Dec 23 18:10:02 +0000 2018</td>\n",
       "      <td>robin8-utils 0.2.0 #Python https://t.co/U1gbtx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sun Dec 23 18:10:03 +0000 2018</td>\n",
       "      <td>HPE to Buy Big Data Infrastructure Startup Blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Sun Dec 23 18:10:03 +0000 2018</td>\n",
       "      <td>RT @trengriffin: Since Santa operates a nonpro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Sun Dec 23 18:10:04 +0000 2018</td>\n",
       "      <td>RT @ThePSF: SciPy 1.2.0 is the culmination of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sun Dec 23 18:10:05 +0000 2018</td>\n",
       "      <td>Machine Learning for Data Science #datascience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Sun Dec 23 18:10:08 +0000 2018</td>\n",
       "      <td>RT @samlightstone: Using big data to predict t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Sun Dec 23 18:10:10 +0000 2018</td>\n",
       "      <td>RT @Piper_Thibodeau: Daily Paint 2223. Snow Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sun Dec 23 18:10:11 +0000 2018</td>\n",
       "      <td>RT @The_Academy_BOT: Hadoop: The Definitive Gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sun Dec 23 18:10:11 +0000 2018</td>\n",
       "      <td>RT @developer_tv: Docker Development WorkFlow‚Ää...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sun Dec 23 18:10:11 +0000 2018</td>\n",
       "      <td>RT @Medium: The most powerful tech companies o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sun Dec 23 18:10:11 +0000 2018</td>\n",
       "      <td>RT @computer__pro: Docker Development WorkFlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Sun Dec 23 18:10:20 +0000 2018</td>\n",
       "      <td>@Madaboutequus @ReclaimTheBody @my_real_name @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Sun Dec 23 18:10:20 +0000 2018</td>\n",
       "      <td>RT @Ananna16: #Discount | 48 Best #Development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sun Dec 23 18:10:26 +0000 2018</td>\n",
       "      <td>RT @Jadirectivestwt: #ChristmasHoliday #Deals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sun Dec 23 18:10:28 +0000 2018</td>\n",
       "      <td>RT @samlightstone: Using big data to predict t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Sun Dec 23 18:07:38 +0000 2018   \n",
       "1   Sun Dec 23 18:07:39 +0000 2018   \n",
       "2   Sun Dec 23 18:07:42 +0000 2018   \n",
       "3   Sun Dec 23 18:07:44 +0000 2018   \n",
       "4   Sun Dec 23 18:07:46 +0000 2018   \n",
       "5   Sun Dec 23 18:07:54 +0000 2018   \n",
       "6   Sun Dec 23 18:08:03 +0000 2018   \n",
       "7   Sun Dec 23 18:08:04 +0000 2018   \n",
       "8   Sun Dec 23 18:08:06 +0000 2018   \n",
       "9   Sun Dec 23 18:08:17 +0000 2018   \n",
       "10  Sun Dec 23 18:08:21 +0000 2018   \n",
       "11  Sun Dec 23 18:08:22 +0000 2018   \n",
       "12  Sun Dec 23 18:08:25 +0000 2018   \n",
       "13  Sun Dec 23 18:08:34 +0000 2018   \n",
       "14  Sun Dec 23 18:08:40 +0000 2018   \n",
       "15  Sun Dec 23 18:08:47 +0000 2018   \n",
       "16  Sun Dec 23 18:08:48 +0000 2018   \n",
       "17  Sun Dec 23 18:08:54 +0000 2018   \n",
       "18  Sun Dec 23 18:09:00 +0000 2018   \n",
       "19  Sun Dec 23 18:09:01 +0000 2018   \n",
       "20  Sun Dec 23 18:09:02 +0000 2018   \n",
       "21  Sun Dec 23 18:09:06 +0000 2018   \n",
       "22  Sun Dec 23 18:09:07 +0000 2018   \n",
       "23  Sun Dec 23 18:09:10 +0000 2018   \n",
       "24  Sun Dec 23 18:09:10 +0000 2018   \n",
       "25  Sun Dec 23 18:09:10 +0000 2018   \n",
       "26  Sun Dec 23 18:09:12 +0000 2018   \n",
       "27  Sun Dec 23 18:09:15 +0000 2018   \n",
       "28  Sun Dec 23 18:09:24 +0000 2018   \n",
       "29  Sun Dec 23 18:09:29 +0000 2018   \n",
       "30  Sun Dec 23 18:09:31 +0000 2018   \n",
       "31  Sun Dec 23 18:09:37 +0000 2018   \n",
       "32  Sun Dec 23 18:09:40 +0000 2018   \n",
       "33  Sun Dec 23 18:09:42 +0000 2018   \n",
       "34  Sun Dec 23 18:09:42 +0000 2018   \n",
       "35  Sun Dec 23 18:09:48 +0000 2018   \n",
       "36  Sun Dec 23 18:09:48 +0000 2018   \n",
       "37  Sun Dec 23 18:09:59 +0000 2018   \n",
       "38  Sun Dec 23 18:10:01 +0000 2018   \n",
       "39  Sun Dec 23 18:10:02 +0000 2018   \n",
       "40  Sun Dec 23 18:10:03 +0000 2018   \n",
       "41  Sun Dec 23 18:10:03 +0000 2018   \n",
       "42  Sun Dec 23 18:10:04 +0000 2018   \n",
       "43  Sun Dec 23 18:10:05 +0000 2018   \n",
       "44  Sun Dec 23 18:10:08 +0000 2018   \n",
       "45  Sun Dec 23 18:10:10 +0000 2018   \n",
       "46  Sun Dec 23 18:10:11 +0000 2018   \n",
       "47  Sun Dec 23 18:10:11 +0000 2018   \n",
       "48  Sun Dec 23 18:10:11 +0000 2018   \n",
       "49  Sun Dec 23 18:10:11 +0000 2018   \n",
       "50  Sun Dec 23 18:10:20 +0000 2018   \n",
       "51  Sun Dec 23 18:10:20 +0000 2018   \n",
       "52  Sun Dec 23 18:10:26 +0000 2018   \n",
       "53  Sun Dec 23 18:10:28 +0000 2018   \n",
       "\n",
       "                                                 text  \n",
       "0   @DShaywitz IMO a combination of factors:\\n- in...  \n",
       "1   OH: ‚ÄúI‚Äôm not doing machine learning or anythin...  \n",
       "2   RT @alainbejjani: Customer experience and big ...  \n",
       "3   Many thanks to @Babatee760 @Cyberdroidmann and...  \n",
       "4   Identity: we are concerned about the use of ou...  \n",
       "5   RT @Deep_In_Depth: Top Python Libraries in 201...  \n",
       "6   RT @vogueandcode: 2019 Goal Setting Today!! üò¨üôå...  \n",
       "7   RT @swardley: \"experience with Wardley Maps\" a...  \n",
       "8   Docker Development WorkFlow‚Ää‚Äî‚Ääa guide with Fla...  \n",
       "9   RT @schmarzo: Good predictions Bill!\\n-Data Mo...  \n",
       "10  Docker Development WorkFlow‚Ää‚Äî‚Ääa guide with Fla...  \n",
       "11  RT @tattoosandbones: Out of over 8000 USGS emp...  \n",
       "12  RT @alexellisuk: Build your own bare-metal ARM...  \n",
       "13          Big Data; The exponential growth of data.  \n",
       "14  „Äê¬•12,600‚Üí¬•1,800„ÄëUdemy„Äé„Äê‰∏ñÁïå„Åß5‰∏á‰∫∫„ÅåÂèóË¨õ„ÄëÂÆüË∑µ Python „Éá„Éº„Çø...  \n",
       "15  I guess it is how you define a wave. Decrease ...  \n",
       "16  RT @whyevernotso: Names for collections of cod...  \n",
       "17  My general suspicion is that decades of manage...  \n",
       "18  RT @Ahmadanii2: Big Data, Meager returns? ‚Äì di...  \n",
       "19  Hadoop: The Definitive Guide https://t.co/Onnp...  \n",
       "20  If statement from a number to infinity https:/...  \n",
       "21  Day: 4/100\\nI started Data Structures and Algo...  \n",
       "22  RT @DrDataScientist: Big Data Processing Engin...  \n",
       "23  RT @developer_tv: Docker Development WorkFlow‚Ää...  \n",
       "24  RT @computer__pro: Docker Development WorkFlow...  \n",
       "25  RT @kdnuggets: 60+ #Free #Books on #BigData, #...  \n",
       "26  RT @IamFarZanaEva: Day: 4/100\\nI started Data ...  \n",
       "27  RT @GurayYildirimTR: Python, R, Pandas, Jupyte...  \n",
       "28  Identity: we say we are  concerned about the u...  \n",
       "29  RT @kdnuggets: 60+ #Free #Books on #BigData, #...  \n",
       "30  RT @CaffeinatedT: #ImTiredOf being broke every...  \n",
       "31  RT @lwp_: #C√≥digo de #Python - Dia de la seman...  \n",
       "32  Filmin giri≈üi Monthy Python The Holy Grail in ...  \n",
       "33  @codemickeycode Glad you asked! It‚Äôs a python ...  \n",
       "34  RT @ThePSF: SciPy 1.2.0 is the culmination of ...  \n",
       "35  Send SMS using Python ‚Äì Shubham Jante ‚Äì Medium...  \n",
       "36  RT @IamFarZanaEva: Day: 4/100\\nI started Data ...  \n",
       "37  RT @sumit12dec: #chatbots #facebook #developer...  \n",
       "38  #Discount | 48 Best #Development Courses \\n\\nh...  \n",
       "39  robin8-utils 0.2.0 #Python https://t.co/U1gbtx...  \n",
       "40  HPE to Buy Big Data Infrastructure Startup Blu...  \n",
       "41  RT @trengriffin: Since Santa operates a nonpro...  \n",
       "42  RT @ThePSF: SciPy 1.2.0 is the culmination of ...  \n",
       "43  Machine Learning for Data Science #datascience...  \n",
       "44  RT @samlightstone: Using big data to predict t...  \n",
       "45  RT @Piper_Thibodeau: Daily Paint 2223. Snow Ba...  \n",
       "46  RT @The_Academy_BOT: Hadoop: The Definitive Gu...  \n",
       "47  RT @developer_tv: Docker Development WorkFlow‚Ää...  \n",
       "48  RT @Medium: The most powerful tech companies o...  \n",
       "49  RT @computer__pro: Docker Development WorkFlow...  \n",
       "50  @Madaboutequus @ReclaimTheBody @my_real_name @...  \n",
       "51  RT @Ananna16: #Discount | 48 Best #Development...  \n",
       "52  RT @Jadirectivestwt: #ChristmasHoliday #Deals ...  \n",
       "53  RT @samlightstone: Using big data to predict t...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo o dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o m√≥dulo Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o m√©todo CountVectorizer para criar uma matriz de documentos\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>co</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>docker</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>big</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>with</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>development</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>guide</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>on</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>learning</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flask</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>postgres</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>are</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>workflow</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bigdata</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>that</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>use</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>it</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>machine</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>we</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>be</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>scipy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>is</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>courses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>coursera</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machinelearning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>more</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>completed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>avgtswffry</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mqzt09rzaw</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>my</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>first</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>datascience</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>amp</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>specialization</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  count\n",
       "0             https     51\n",
       "1                co     51\n",
       "2                rt     32\n",
       "3              data     24\n",
       "4            python     22\n",
       "5               the     21\n",
       "6               and     20\n",
       "7                of     20\n",
       "8                to     13\n",
       "9            docker     13\n",
       "10               in     12\n",
       "11              for     11\n",
       "12              big     10\n",
       "13             with      9\n",
       "14      development      8\n",
       "15            guide      8\n",
       "16               on      8\n",
       "17         learning      7\n",
       "18             this      6\n",
       "19            flask      6\n",
       "20         postgres      6\n",
       "21              day      6\n",
       "22              are      6\n",
       "23         workflow      6\n",
       "24          bigdata      5\n",
       "25           hadoop      5\n",
       "26             that      5\n",
       "27              use      5\n",
       "28               it      5\n",
       "29          machine      5\n",
       "30               we      5\n",
       "31               be      4\n",
       "32       algorithms      4\n",
       "33            scipy      4\n",
       "34               is      4\n",
       "35          courses      3\n",
       "36         coursera      3\n",
       "37  machinelearning      3\n",
       "38             more      3\n",
       "39        completed      3\n",
       "40             best      3\n",
       "41       avgtswffry      3\n",
       "42       mqzt09rzaw      3\n",
       "43               my      3\n",
       "44            first      3\n",
       "45      datascience      3\n",
       "46           medium      3\n",
       "47              100      3\n",
       "48              amp      3\n",
       "49   specialization      3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contando o n√∫mero de ocorr√™ncias das principais palavras em nosso dataset\n",
    "word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\n",
    "word_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\n",
    "word_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "word_count[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
